{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score,precision_score\n",
    "import os\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from pprint import pprint\n",
    "from sklearn.inspection import permutation_importance\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'C:\\Users\\javad\\OneDrive - University of Windsor\\Shirin Research\\research\\ML Codes\\Data_VIF.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Warning       933\n",
       "Alert          388\n",
       "Stable         316\n",
       "Sustainable    309\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Label','Year'],axis=1)\n",
    "y=df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We implement the GridSeach to do the hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'n_estimators': [10, 20, 50, 100, 150,200,250,300],\n",
    "    'criterion':[\"gini\",\"entropy\", \"log_loss\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(rf_model, model_params, n_jobs=-1,cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'entropy',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 150,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[176   4   1   0]\n",
      " [ 14  70   0   0]\n",
      " [  6   0  56   2]\n",
      " [  0   0   6  55]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Warning       0.90      0.97      0.93       181\n",
      "       Alert       0.95      0.83      0.89        84\n",
      "      Stable       0.89      0.88      0.88        64\n",
      " Sustainable       0.96      0.90      0.93        61\n",
      "\n",
      "    accuracy                           0.92       390\n",
      "   macro avg       0.92      0.90      0.91       390\n",
      "weighted avg       0.92      0.92      0.91       390\n",
      "\n",
      "Accuracy: 0.9153846153846154\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print('Classification Report:',)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy:',result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over sampling Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_over=df_over.drop(['Label','Year'],axis=1)\n",
    "y_over=df_over['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_over, y_over = oversample.fit_resample(x_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alert          933\n",
       " Warning       933\n",
       "Stable         933\n",
       "Sustainable    933\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_train, X_over_test, y_over_train, y_over_test = train_test_split(x_over,y_over,test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_over = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_over = GridSearchCV(rf_model_over, model_params, n_jobs=-1,cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over = clf_over.fit(X_over_train, y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'entropy',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 150,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_over.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_over = model_over.predict(X_over_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[184  14   6   0]\n",
      " [ 14 179   0   0]\n",
      " [  2   0 171   2]\n",
      " [  0   0   3 172]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Warning       0.92      0.90      0.91       204\n",
      "       Alert       0.93      0.93      0.93       193\n",
      "      Stable       0.95      0.98      0.96       175\n",
      " Sustainable       0.99      0.98      0.99       175\n",
      "\n",
      "    accuracy                           0.95       747\n",
      "   macro avg       0.95      0.95      0.95       747\n",
      "weighted avg       0.95      0.95      0.94       747\n",
      "\n",
      "Accuracy: 0.9451137884872824\n"
     ]
    }
   ],
   "source": [
    "result_over = confusion_matrix(y_over_test,y_pred_over)\n",
    "print('Confusion Matrix:')\n",
    "print(result_over)\n",
    "result1_over = classification_report(y_over_test,y_pred_over)\n",
    "print('Classification Report:',)\n",
    "print (result1_over)\n",
    "result2_over = accuracy_score(y_over_test,y_pred_over)\n",
    "print('Accuracy:',result2_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under sampling Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_under=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_under=df_under.drop(['Label','Year'],axis=1)\n",
    "y_under=df_under['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = NearMiss(version=1, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_under, y_under= undersample.fit_resample(x_under,y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Warning       309\n",
       "Alert          309\n",
       "Stable         309\n",
       "Sustainable    309\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(x_under,y_under,test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_under = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_under = GridSearchCV(rf_model_under, model_params, n_jobs=-1,cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_under = clf_under.fit(X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 300,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_under.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_under = model_under.predict(X_under_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[67  4  2  1]\n",
      " [ 3 50  0  0]\n",
      " [ 0  1 51  3]\n",
      " [ 0  0  6 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Warning       0.96      0.91      0.93        74\n",
      "       Alert       0.91      0.94      0.93        53\n",
      "      Stable       0.86      0.93      0.89        55\n",
      " Sustainable       0.94      0.91      0.92        66\n",
      "\n",
      "    accuracy                           0.92       248\n",
      "   macro avg       0.92      0.92      0.92       248\n",
      "weighted avg       0.92      0.92      0.92       248\n",
      "\n",
      "Accuracy: 0.9193548387096774\n"
     ]
    }
   ],
   "source": [
    "result_under = confusion_matrix(y_under_test,y_pred_under)\n",
    "print('Confusion Matrix:')\n",
    "print(result_under)\n",
    "result1_under = classification_report(y_under_test,y_pred_under)\n",
    "print('Classification Report:',)\n",
    "print (result1_under)\n",
    "result2_under = accuracy_score(y_under_test,y_pred_under)\n",
    "print('Accuracy:',result2_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04709458, 0.30058015, 0.11821947, 0.15784942, 0.29290476,\n",
       "       0.08335162])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_over.best_estimator_.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GDP growth', 'GDP per capita', 'Population', 'School enrolment ',\n",
       "       'Corruption', 'Regime types'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_over.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {'Feature': ['GDP growth', 'GDP per capita', 'Population', 'School enrolment ',\n",
    "       'Corruption', 'Regime types'], 'Feature Importance': [0.04709458, 0.30058015, 0.08335162, 0.15784942, 0.29290476,\n",
    "       0.11821947]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GDP growth</td>\n",
       "      <td>0.047095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDP per capita</td>\n",
       "      <td>0.300580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Population</td>\n",
       "      <td>0.083352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School enrolment</td>\n",
       "      <td>0.157849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corruption</td>\n",
       "      <td>0.292905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Regime types</td>\n",
       "      <td>0.118219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Feature Importance\n",
       "0         GDP growth            0.047095\n",
       "1     GDP per capita            0.300580\n",
       "2         Population            0.083352\n",
       "3  School enrolment             0.157849\n",
       "4         Corruption            0.292905\n",
       "5       Regime types            0.118219"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2=pd.DataFrame(data2)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
